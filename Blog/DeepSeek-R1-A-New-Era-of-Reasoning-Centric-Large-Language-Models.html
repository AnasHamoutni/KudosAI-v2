<!DOCTYPE html>
<html lang="en" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>Kudos AI | Blog | DeepSeek R1: A New Era of Reasoning-Centric Large Language Models</title>
    
    <!-- SEO Meta Tags -->
    <meta name="description" content="DeepSeek R1: A New Era of Reasoning-Centric Large Language Models. Explore its advanced architecture, training methodology, applications, industry impact, code implementations, challenges, and future research directions.">
    <meta name="keywords" content="DeepSeek R1, Large Language Models, AI, Transformer, Mixture-of-Experts, Reinforcement Learning, Chain-of-Thought, Code Generation, GPT-4, Llama, Mistral">
    
    <!-- Bootstrap and Font Awesome CSS -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/css/bootstrap.min.css">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.2.0/css/all.min.css">
    
    <!-- Link to your external styles.css for additional styling -->
    <link rel="stylesheet" href="styles.css"/>
    
    <!-- Highlight.js -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/styles/default.min.css">
    <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.0.3/highlight.min.js"></script>
    <script>hljs.initHighlightingOnLoad();</script>

    <!-- Google Tag Manager -->
    <script>(function(){var analyticsId="G-VCL644R1SZ";try{var consent=localStorage.getItem("kudosCookieConsent");if(consent!=="accepted"){window["ga-disable-"+analyticsId]=true;}}catch(e){window["ga-disable-"+analyticsId]=true;}})();</script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-VCL644R1SZ"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
      gtag('config', 'G-VCL644R1SZ');
    </script>
    
    <link rel="icon" type="image/x-icon" href="Kudos_AI_favicon.png">
    
    <!-- Including MathJax for equation rendering -->
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    
    <!-- Explicit Inline Styles for Article-Specific Coloring and Formatting -->
    <style>
      .highlight {
        color: #007bff;
        font-weight: bold;
      }
      p {
        margin-bottom: 1em;
      }
.video-container {
    position: relative;
    padding-bottom: 56.25%; /* 16:9 aspect ratio */
    height: 0;
    overflow: hidden;
    max-width: 100%;
    background: #000;
    margin: 0 auto; /* Center the video */
    border-radius: 12px; /* Round corners for the container */
}

.video-container iframe {
    position: absolute;
    top: 0;
    left: 0;
    width: 100%;
    height: 100%;
    border-radius: 12px; /* Round corners for the iframe */
}
    pre code {
        background-color: #f8f9fa;
        border: 1px solid #e0e0e0;
        border-radius: 5px;
        padding: 10px;
        display: block;
        white-space: pre-wrap; /* Allows wrapping of long lines */
        word-wrap: break-word; /* Prevents overflow */
        font-family: Consolas, 'Courier New', monospace;
        font-size: 18px;
    }
      .image-container {
        text-align: center;
        margin: 20px 0;
      }

      .responsive-image {
        max-width: 100%;
        height: auto;
        display: inline-block;
        border-radius: 8px;
      }
.scroll-indicator {
  position: relative;
  overflow-x: auto;
}

.math-equation {
  font-family: "Courier New", monospace;
  padding: 5px;
  border-radius: 4px;
  display: block;
  max-width: 100%;
  white-space: nowrap; /* Prevent wrapping so the scroll bar appears */
  word-break: normal; /* Don't break words */
  background-color: transparent;
  text-align: center;
  margin: 10px auto;
}
      h3 {
        text-align: center;
      }

      h4 {
        text-align: left;
      }


    </style>
   </head>
  <body>
    <!-- Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-light" style="background-color: white;">
      <a class="navbar-brand" href="/index.html">
        <img width="180px" src="/Kudos_AI_logo_transparent.png" alt="Kudos AI Logo">
      </a>
      <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#myNavbarToggler10" 
              aria-controls="myNavbarToggler10" aria-expanded="false" aria-label="Toggle navigation">
        <span class="navbar-toggler-icon"></span>
      </button>
      <div class="collapse navbar-collapse" id="myNavbarToggler10">
        <ul class="navbar-nav mx-auto">
          <li class="nav-item"><a class="nav-link" href="/index.html">Home</a></li>
          <li class="nav-item"><a class="nav-link" href="/Blog.html">Blog</a></li>
          <li class="nav-item"><a class="nav-link" href="/Projects.html">Projects</a></li>
          <li class="nav-item"><a class="nav-link" href="/About-me.html">About</a></li>
          <li class="nav-item"><a class="nav-link" href="/Get-in-Touch.html">Get in Touch</a></li>
        </ul>
        <ul class="navbar-nav sm-icons mr-0 d-flex justify-content-center">
          <li class="nav-item"><a class="nav-link" target="_blank" href="https://www.linkedin.com/in/hamoutni/">
            <i class="fa-brands fa-linkedin-in" style="margin-top: 7px;"></i></a></li>
          <li class="nav-item"><a class="nav-link" target="_blank" href="https://www.kaggle.com/anashamoutni">
            <i class="fab fa-kaggle"></i></a></li>
          <li class="nav-item"><a class="nav-link" target="_blank" href="https://github.com/AnasHamoutni">
            <i class="fab fa-github" style="margin-top: 7px;"></i></a></li>
          <li class="nav-item"><a class="nav-link" target="_blank" href="https://x.com/anashamoutni">
            <i class="fab fa-x-twitter" style="margin-top: 7px;"></i></a></li>
        </ul>
      </div>
    </nav>
    
    <!-- Blog Post Content -->
    <div class="blogPost-div">
      <img class="imgPost" loading="lazy" src="Deepseek_v3.png" alt="DeepSeek R1 Banner Image">
      <div class="blogPost-title-div">
        <h2 class="blogPost-title">DeepSeek R1: A New Era of Reasoning-Centric Large Language Models</h2>
      </div>
      <div class="postBody-div">
        <!-- 1. Introduction -->
        <p>
          <span class="highlight"><a href="https://en.wikipedia.org/wiki/Large_language_model" target="_blank">Large language models (LLMs)</a></span> are transforming AI.
          <br>DeepSeek R1 is an <span class="highlight"><a href="https://en.wikipedia.org/wiki/Open-source" target="_blank">open-source</a></span> model that emphasizes <span class="highlight"><a href="https://en.wikipedia.org/wiki/Reasoning" target="_blank">reasoning</a></span>.
          It rivals closed models such as <span class="highlight"><a href="https://en.wikipedia.org/wiki/GPT-4" target="_blank">GPT-4</a></span> and <span class="highlight"><a href="https://en.wikipedia.org/wiki/Llama_(model)" target="_blank">Llama</a></span>.
        </p>
        <p>
          Introduced in January 2025, DeepSeek R1 builds on previous systems like DeepSeek-V3. Its efficient design offers comparable performance to top-tier systems at a lower cost.
          This article explores its architecture, training pipeline, and diverse applications.
        </p>
        
        <center><hr align="center" width="50%" class="solid"></center>
        
        <!-- 2. Technical Architecture -->
        <h3 style="text-align:center; color:blue; margin-bottom:30px; margin-top:35px;">1. Technical Architecture</h3>
        <center><hr align="center" width="50%" class="solid"></center>
        <p>
          DeepSeek R1 is based on the <span class="highlight"><a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" target="_blank">Transformer</a></span> architecture.
          It tokenizes text into subword units and converts them into embeddings. Multiple self-attention layers capture both local and global dependencies.
        </p>
        <p>
          A key innovation is the <span class="highlight"><a href="https://en.wikipedia.org/wiki/Mixture-of-experts" target="_blank">Mixture-of-Experts (MoE)</a></span> design.
          With a total of <em>671 billion parameters</em>, only about <em>37 billion</em> are active per token, thanks to a dynamic routing system.
        </p>
        <p>
          This dynamic routing enables expert specialization. For example, one group of experts may focus on code, while others excel in math.
        </p>
        <img class="imgPost" loading="lazy" style="width:85%; margin-bottom:20px;"src="MoE-diagram.jpg" alt="MoE Architecture Diagram">
        <p>
          The core self-attention operation is defined as:
        </p>
        <div class="scroll-indicator">
          <div class="math-equation">
            $$ \text{Attention}(Q, K, V) = \text{softmax}\Big(\frac{QK^T}{\sqrt{d_k}}\Big)V $$
          </div>
        </div>
        <p>
          Here, <span class="highlight"><a href="https://en.wikipedia.org/wiki/Query_(information_retrieval)" target="_blank">Query (Q)</a></span>,
          <span class="highlight"><a href="https://en.wikipedia.org/wiki/Key_(cryptography)" target="_blank">Key (K)</a></span>, and
          <span class="highlight"><a href="https://en.wikipedia.org/wiki/Value_(computer_science)" target="_blank">Value (V)</a></span>
          matrices are derived from the input embeddings.
        </p>
        <p>
          Advanced positional encoding strategies (e.g. rotary embeddings) support its extended context of up to <em>128K tokens</em>.
          This is a major leap over models like GPT-4 or Llama 2.
        </p>
        <p>
          Additionally, the backbone supports a <span class="highlight"><a href="https://en.wikipedia.org/wiki/Chain-of-thought" target="_blank">chain-of-thought</a></span> output.
          The model displays reasoning steps within <code>&lt;think&gt;</code> tags, enhancing transparency.
        </p>
        
        <center><hr align="center" width="50%" class="solid"></center>
        
        <!-- 3. Training Methodology -->
        <h3 style="text-align:center; color:blue; margin-bottom:30px; margin-top:35px;">2. Training Methodology</h3>
        <center><hr align="center" width="50%" class="solid"></center>
        <p>
          DeepSeek R1 was trained using a multi-stage pipeline that goes beyond the traditional pretrain–fine-tune model.
        </p>
        <ul>
          <li>
            <strong style="color:blue;">Base Pre-training:</strong> The model was pre-trained on about <em>14.8 trillion tokens</em> using FP8 mixed precision for efficiency. This phase used roughly <em>2.788 million GPU-hours</em> on NVIDIA H800-class hardware.
          </li>
          <li>
            <strong style="color:blue;">Reinforcement Learning Phase 1 (R1-Zero):</strong> The model was directly optimized using a rule-based reward system. It was rewarded for both correct answers and for producing a detailed <span class="highlight"><a href="https://en.wikipedia.org/wiki/Chain-of-thought" target="_blank">chain-of-thought</a></span> output.
          </li>
          <li>
            <strong style="color:blue;">Supervised Fine-Tuning (SFT):</strong> Curated examples were used to refine the model’s style, ensuring clarity and language consistency.
          </li>
          <li>
            <strong style="color:blue;">Reinforcement Learning Phase 2 (Alignment):</strong> Additional rewards emphasized concise, helpful responses while keeping the chain-of-thought intact.
          </li>
          <li>
            <strong style="color:blue;">Model Distillation:</strong> The full 671B MoE model was compressed into smaller variants (7B, 14B, 32B) for broader accessibility.
          </li>
        </ul>
        <p>
          Ethical considerations and bias mitigation were integral to the training. Although the model inherits biases from its training data, its open-source nature enables community oversight.
        </p>
        
        <center><hr align="center" width="50%" class="solid"></center>
        
        <!-- 4. Applications and Use Cases -->
        <h3 style="text-align:center; color:blue; margin-bottom:30px; margin-top:35px;">3. Applications and Use Cases</h3>
        <center><hr align="center" width="50%" class="solid"></center>
        <p>
          DeepSeek R1’s advanced reasoning and long-context capabilities unlock many applications:
        </p>
        <ul>
          <li>
            <strong style="color:blue;">Complex Problem Solving:</strong> The model breaks down challenging math and logic problems into clear, digestible steps. For instance, it can tutor students by explaining calculus or proving theorems.
          </li>
          <li>
            <strong style="color:blue;">Code Generation and Debugging:</strong> With an Elo rating of over 2000 on platforms like 
            <span class="highlight"><a href="https://en.wikipedia.org/wiki/Codeforces" target="_blank">Codeforces</a></span>, it excels in generating, reviewing, and optimizing code.
          </li>
          <li>
            <strong style="color:blue;">Knowledge Assistance:</strong> Its extended context (up to 128K tokens) enables it to summarize legal documents, scientific papers, and enterprise reports.
          </li>
          <li>
            <strong style="color:blue;">Creative Writing:</strong> DeepSeek R1 can generate engaging content and explain its reasoning, making it a valuable tool for writers and marketers.
          </li>
          <li>
            <strong style="color:blue;">Long-Context Analysis:</strong> It can sift through contracts or meeting transcripts to deliver targeted insights.
          </li>
          <li>
            <strong style="color:blue;">Research and Development:</strong> The model’s detailed chain-of-thought outputs are used to generate training data for specialized, smaller models.
          </li>
        </ul>
        <p>
          Enterprises are exploring its integration into customer support systems and financial analysis tools to provide transparent, data-driven insights.
        </p>
        
        <div class="video-container" style="width: 95%; margin: 0 auto;">
          <iframe title="DeepSeek R1 Overview" src="https://www.youtube.com/embed/_CXwZ5xyFno" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
        <br>
				<p>
          This video provides an overview of DeepSeek R1’s innovative architecture and real-world applications.
        </p>
        
        <center><hr align="center" width="50%" class="solid"></center>
        
        <!-- 5. Code Implementation -->
        <h3 style="text-align:center; color:blue; margin-bottom:30px; margin-top:35px;">4. Code Implementation</h3>
        <center><hr align="center" width="50%" class="solid"></center>
        <p>
          The snippet below demonstrates how to load a distilled version of DeepSeek R1 using the <span class="highlight"><a href="https://huggingface.co/transformers" target="_blank">Transformers</a></span> library.
        </p>
        <div class="scroll-indicator">
          <pre><code class="language-python">
import torch
from transformers import AutoTokenizer, AutoModelForCausalLM

# Load DeepSeek-R1 Distilled (Qwen-7B variant)
model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-7B"
tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)
model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16, device_map="auto")

# Define a complex question with a chain-of-thought prompt
question = "Q: What is the sum of the first 10 prime numbers? Let's think step by step.\nA:"
inputs = tokenizer(question, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=256, do_sample=False, temperature=0.0)
response = tokenizer.decode(outputs[0], skip_special_tokens=True)

print(response)
          </code></pre>
        </div>
        <p>
          The output may include a detailed chain-of-thought trace, for example:
        </p>
        <div class="scroll-indicator">
          <div class="math-equation">
            &lt;think&gt; The first 10 prime numbers are 2, 3, 5, 7, 11, 13, 17, 19, 23, 29.
            Summing them step by step gives 129. &lt;/think&gt; 129
          </div>
        </div>
        <p>
          This transparency helps verify the final answer and aids in debugging.
        </p>
        <p>
          Another example is using DeepSeek R1 for code generation. Consider this prompt for a Python function to check if a number is prime:
        </p>
        <div class="scroll-indicator">
          <pre><code class="language-python">
# A prompt for code generation
code_prompt = "Q: Write a Python function to check if a number is prime.\nA:"
inputs = tokenizer(code_prompt, return_tensors="pt").to("cuda")
outputs = model.generate(**inputs, max_new_tokens=200, temperature=0.2)
print(tokenizer.decode(outputs[0], skip_special_tokens=True))
          </code></pre>
        </div>
        <p>
          The model may output code along with its reasoning, enhancing clarity and trust.
        </p>
        
        <center><hr align="center" width="50%" class="solid"></center>
        
        <!-- 6. Challenges and Limitations -->
        <h3 style="text-align:center; color:blue; margin-bottom:30px; margin-top:35px;">5. Challenges and Limitations</h3>
        <center><hr align="center" width="50%" class="solid"></center>
        <p>
          Despite its advanced capabilities, DeepSeek R1 faces several challenges:
        </p>
        <ul>
          <li><strong style="color:blue;">Resource Intensity:</strong> With 671B parameters (37B active per token), it requires significant computing power. Even with MoE reducing per-token costs, real-time deployment needs high-end infrastructure.</li>
          <li><strong style="color:blue;">Complexity of MoE:</strong> The dynamic routing adds challenges in fine-tuning and deployment. Balancing expert usage often requires custom engineering solutions.</li>
          <li><strong style="color:blue;">Emergent Behaviors:</strong> The reinforcement learning approach may cause overly verbose outputs. While the chain-of-thought is valuable, in casual use users might prefer concise answers.</li>
          <li><strong style="color:blue;">Knowledge Cutoff:</strong> Its training data is current up to around 2024. In rapidly changing fields, this can result in outdated or incorrect information.</li>
          <li><strong style="color:blue;">Bias and Ethics:</strong> The model inherits biases from its training data. Ongoing monitoring and community oversight are essential to mitigate potential issues.</li>
          <li><strong style="color:blue;">Long-Context Challenges:</strong> Handling up to 128K tokens is innovative, but extended contexts can slow processing and dilute focus if too much text is provided.</li>
          <li><strong style="color:blue;">Evaluation and Trust:</strong> Benchmark scores are strong, but real-world performance may vary, particularly in nuanced or commonsense reasoning tasks.</li>
        </ul>
        <p>
          These challenges emphasize the need for continuous research and iterative improvements. Future iterations (e.g., DeepSeek R2) are expected to address these limitations.
        </p>
        
        <center><hr align="center" width="50%" class="solid"></center>
        
        <!-- 7. Industry Impact and Future Directions -->
        <h3 style="text-align:center; color:blue; margin-bottom:30px; margin-top:35px;">6. Industry Impact and Future Directions</h3>
        <center><hr align="center" width="50%" class="solid"></center>
        <p>
          DeepSeek R1 marks a turning point for both research and industry. Its open-source nature and state-of-the-art reasoning capabilities promote collaboration and innovation.
        </p>
        <p>
          Enterprises in finance, healthcare, and customer support are already exploring its integration. Its ability to process long documents enables in-depth report analysis, risk assessment, and enhanced decision-making.
        </p>
        <p>
          Looking ahead, multi-modal models that combine text with images or audio are on the horizon. Researchers are exploring how to integrate external tools (e.g., calculators or databases) directly into the reasoning process.
        </p>
        <p>
          The community-driven development model ensures continuous feedback, and distilled variants make the technology accessible to organizations with limited resources. Experts predict these models will soon be standard in fields requiring transparent reasoning.
        </p>
        <p>
          Future research aims to further compress models without sacrificing performance, improve the interpretability of chain-of-thought outputs, and develop robust safety protocols.
        </p>
        
        <center><hr align="center" width="50%" class="solid"></center>
        
        <!-- 8. Conclusion -->
        <h3 style="text-align:center; color:blue; margin-bottom:30px; margin-top:35px;">7. Conclusion</h3>
        <center><hr align="center" width="50%" class="solid"></center>
        <p>
          DeepSeek R1 is a monumental achievement in large language models. By combining a powerful <span class="highlight"><a href="https://en.wikipedia.org/wiki/Mixture-of-experts" target="_blank">Mixture-of-Experts</a></span> architecture with innovative <span class="highlight"><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank">reinforcement learning</a></span> techniques, it achieves advanced reasoning and problem-solving capabilities that were once limited to proprietary systems.
        </p>
        <p>
          Its design emphasizes transparency through chain-of-thought outputs, allowing users to see not only the final answers but also the reasoning behind them.
        </p>
        <p>
          This article has examined DeepSeek R1’s technical architecture, multi-stage training pipeline, diverse applications, and the challenges it faces. It also discussed the significant industry impact and future directions for reasoning-centric AI.
        </p>
        <p>
          As research continues and community contributions drive further improvements, AI systems will not only solve complex problems but also explain their reasoning in a human-like manner. This transparency is essential for building trust and ensuring responsible deployment.
        </p>
        <p>
          In conclusion, DeepSeek R1 is not just another large language model—it is a comprehensive platform for reasoning-centric AI that sets a new benchmark in the field and offers a glimpse into the future of autonomous, explainable AI.
        </p>
        <p>
          For further reading and technical details, please consult:
        </p>
        <ul>
          <li><span class="highlight"><a href="https://arxiv.org/abs/2501.12948" target="_blank">DeepSeek R1 Technical Report</a></span></li>
          <li><span class="highlight"><a href="https://arxiv.org/abs/2406.18219" target="_blank">Mixture-of-Experts in Language Models</a></span></li>
          <li><span class="highlight"><a href="https://arxiv.org/abs/1706.03762" target="_blank">Attention is All You Need</a></span></li>
          <li><span class="highlight"><a href="https://en.wikipedia.org/wiki/Reinforcement_learning" target="_blank">Reinforcement Learning</a></span></li>
        </ul>
        <p>
          This comprehensive article has provided an in-depth look into DeepSeek R1’s innovations, applications, challenges, and future directions—marking a new era in reasoning-centric AI.
        </p>
      </div>
    </div>
    
    <!-- Footer -->
    
    <!-- COMMENTS SECTION -->
    <section class="comments-section">
      <h3>Comments</h3>
      
      <form id="comment-form" class="comment-form">
        <label for="comment-name">Name *</label>
        <input type="text" id="comment-name" placeholder="Your name" required>
        
        <label for="comment-email">Email *</label>
        <input type="email" id="comment-email" placeholder="Your email (not displayed)" required>
        
        <label for="comment-password">Password *</label>
        <input type="password" id="comment-password" placeholder="Create a password (for deleting later)" required>
        <p class="form-note">Remember this password - you will need it to delete your comment.</p>
        
        <label for="comment-text">Comment *</label>
        <textarea id="comment-text" placeholder="Write your comment..." required></textarea>
        
        <button type="submit" class="submit-btn">Post Comment</button>
      </form>
      
      <div id="comments-list" class="comments-list"></div>
    </section>

<footer class="footer">
      <div class="waves">
        <div class="wave" id="wave1"></div>
        <div class="wave" id="wave2"></div>
        <div class="wave" id="wave3"></div>
      </div>
      <div class="footer-elem-container">
        <ul class="social-icon">
          <li class="social-icon__item">
            <a class="social-icon__link" href="https://www.linkedin.com/in/hamoutni/" target="_blank">
              <ion-icon name="logo-linkedIn"></ion-icon>
            </a>
          </li>
          <li class="social-icon__item">
            <a class="social-icon__link" href="https://www.kaggle.com/anashamoutni" target="_blank">
              <i class="fab fa-kaggle"></i>
            </a>
          </li>
          <li class="social-icon__item">
            <a class="social-icon__link" href="https://github.com/AnasHamoutni" target="_blank">
              <ion-icon name="logo-github"></ion-icon>
            </a>
          </li>
          <li class="social-icon__item">
            <a class="social-icon__link" href="https://x.com/anashamoutni" target="_blank">
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 462.799" width="32" height="32" style="vertical-align: baseline;">
                <path fill="#fff" fill-rule="nonzero" d="M403.229 0h78.506L310.219 196.04 512 462.799H354.002L230.261 301.007 88.669 462.799h-78.56l183.455-209.683L0 0h161.999l111.856 147.88L403.229 0zm-27.556 415.805h43.505L138.363 44.527h-46.68l283.99 371.278z"/>
              </svg>
            </a>
          </li>
        </ul>
    <ul class="menu">
      <li class="menu__item"><a class="menu__link" href="/index.html">Home</a></li>
      <li class="menu__item"><a class="menu__link" href="/Blog.html">Blog</a></li>
          <li class="menu__item"><a class="menu__link" href="/Projects.html">Projects</a></li>
          <li class="menu__item"><a class="menu__link" href="/About-me.html">About</a></li>
      <li class="menu__item"><a class="menu__link" href="/Get-in-Touch.html">Get in Touch</a></li>
      <li class="menu__item"><a class="menu__link" href="/Privacy-Policy.html">Privacy Policy</a></li>
	  <li class="menu__item"><a class="menu__link" href="/Terms-of-Service.html">Terms of Service</a></li>
	  <li class="menu__item"><a class="menu__link" href="/Cookie-Policy.html">Cookie Policy</a></li>
    </ul>
<div class="p-foot-div">
    <p>&copy;<span class="js-copyright-year">2025</span> Kudos AI • by Anas HAMOUTNI • All Rights Reserved</p>
</div>
</div>
    </footer>
    
    <!-- Scripts -->
    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" 
            integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" 
            crossorigin="anonymous"></script>
    <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.2.1/js/bootstrap.min.js" 
            integrity="sha384-B0UglyR+jN6CkvvICOB2joaf5I4l3gm9GU6Hc1og6Ls7i6U/mkkaduKaBhlAXv9k" 
            crossorigin="anonymous" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js" 
            integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7N" 
            crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.2.1/jquery.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/4.1.3/js/bootstrap.bundle.min.js" defer></script>
    <script type="module" src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.esm.js"></script>
    <script nomodule src="https://unpkg.com/ionicons@5.5.2/dist/ionicons/ionicons.js"></script>
    <script src='https://kit.fontawesome.com/d25a67fa19.js' crossorigin='anonymous' defer></script>
    <script src="/index.js" defer></script>
      <script src="/comments.js" defer></script>
</body>
</html>
